# *Phase 5: Modeling & Signal Development**

In **Objectives & Scope**, Phase 5 is designed to transform engineered features from earlier phases into predictive ranking models that generate actionable trading signals. The measurable goal is to achieve robust cross-sectional stock rankings validated through Information Coefficient (IC) and turnover-adjusted Sharpe ratio. Deliverables include documentation (`docs/phase5_objectives.md`) and a fully integrated modeling framework that can toggle across baseline and advanced models. The key consideration is ensuring models balance interpretability, computational cost, and predictive performance.

For **Universe / Asset Selection**, this phase continues to focus on the S&P 500, or a configurable top-K subset defined earlier in Phase 2. Tickers are pulled from a centralized CSV file (`data/universe/sp500_constituents.csv`) and linked to processed feature sets. Considerations here include survivorship bias (ensuring only historically valid constituents are used in backtests) and whether subsets should remain static (fixed top-K) or evolve dynamically later.

Under **Data Sources & APIs**, Phase 5 leverages features and metrics generated in Phases 2 and 3, with no new raw market data introduced at this stage. Configurations for modeling sources are kept in `config/models.yaml`, which defines model families and hyperparameters. Considerations include ensuring alignment between preprocessed data formats and model input requirements, as well as controlling for temporal leakage during feature ingestion.

For **Data Acquisition & Storage**, modeling consumes Parquet or Feather-optimized feature datasets generated in earlier phases. The pipeline ensures partitioning by ticker and date, with versioning handled through hash tracking and metadata logs. Cleaned features are stored in `data/processed/features/` and linked directly into modeling scripts. Considerations here involve ensuring raw vs adjusted feature versions are distinguishable and supporting batch vs rolling window access patterns for training.

Within **Feature Engineering / Analysis**, Phase 5 makes heavy use of liquidity, volatility, and trendiness metrics already defined in Phase 3. Additional transformations include cross-sectional normalization, lagging features to prevent lookahead bias, and rolling-window stability checks. Deliverables include plots of IC over time, tables of feature importance, and a finalized library of normalized features stored in `data/processed/ml_ready/`. Considerations include whether to adopt pairwise ranking losses early or stick with regression + rank conversion for simplicity, as well as validating that engineered features remain stable across different market regimes.

The **Infrastructure / Pipeline** component introduces modular model wrappers in `src/models/`, including baseline logistic and ridge regression, gradient-boosted trees (LightGBM/XGBoost), optional LambdaMART for direct ranking, and ensembles of weak learners. A GPU-enabled path is prepared for sequence-based models (LSTM/Transformer), but these are only deployed if gradient boosting saturates performance. Caching, error handling, and logs (`logs/model_training/`) are built into the training pipeline. Considerations include CPU-first workflows for cost efficiency and a flexible YAML-driven toggle for model selection.

In **Evaluation / Success Metrics**, IC and Rank IC are established as the **primary development metrics**, ensuring the models align with the ranking objective. Sharpe ratio and turnover-adjusted PnL are designated as **secondary business validation metrics** to confirm economic value. Deliverables include `src/evaluation/metrics.py`, YAML configs for thresholds, and `reports/model_eval.md` containing plots, tables, and commentary. The main consideration is that strong IC is necessary but not sufficient â€” Sharpe validation ensures the signals have tradable value.

The **Constraints & Assumptions** for Phase 5 include prioritizing retail-level compute environments. CPU suffices for logistic regression, ridge, and GBM training, while GPU planning is in place but postponed until sequence models are required. Time splits are handled strictly temporally to avoid leakage, with a default walk-forward expanding window configuration. Assumptions include focusing only on regular trading hours (RTH) and a manageable dataset size due to earlier storage and batching strategies.

For **Version Control / Reproducibility**, every model run is tied to a config and metadata snapshot. GitHub manages code versioning, while training logs and metrics outputs are stored in `logs/model_training/`. Full dataset versioning is avoided to conserve storage; instead, hash tracking ensures that models can be traced back to the exact feature inputs used. Considerations include whether to eventually integrate external experiment tracking (e.g., MLflow or W&B), though Phase 5 proceeds with lightweight YAML + logs.

Finally, in **Iteration / Next Steps**, Phase 5 sets the foundation for Phase 6 (Backtesting & Portfolio Construction). Once models demonstrate stable IC and positive Sharpe proxy, their predictions will be converted into portfolio weights and tested against historical trading simulations. Unresolved questions at this stage include whether pairwise ranking losses should be prioritized later and how to balance the tradeoff between predictive strength and turnover costs. Deliverables include `docs/phase5_next_steps.md`, linking directly into Phase 6 requirements.
